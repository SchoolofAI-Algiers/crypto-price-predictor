{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptoPricePredictionPipeline:\n",
    "    def __init__(self, csv_path):\n",
    "        # Load the data\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Feature selection (excluding time-based columns)\n",
    "        features = ['Open', 'High', 'Low', 'Volume', \n",
    "                    'Quote_Asset_Volume', 'Number_of_Trades', \n",
    "                    'Taker_Buy_Base_Volume', 'Taker_Buy_Quote_Volume']\n",
    "        target = 'Close'\n",
    "        \n",
    "        # Separate features and target\n",
    "        self.X = self.df[features].values\n",
    "        self.y = self.df[target].values\n",
    "        \n",
    "        # Initialize scaler\n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_y = StandardScaler()\n",
    "        \n",
    "    def prepare_data(self, test_size=0.2, random_state=42):\n",
    "        # Scale features and target\n",
    "        X_scaled = self.scaler_X.fit_transform(self.X)\n",
    "        y_scaled = self.scaler_y.fit_transform(self.y.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, y_scaled, \n",
    "            test_size=test_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        self.X_train = torch.FloatTensor(X_train)\n",
    "        self.X_test = torch.FloatTensor(X_test)\n",
    "        self.y_train = torch.FloatTensor(y_train)\n",
    "        self.y_test = torch.FloatTensor(y_test)\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_dataset = TensorDataset(self.X_train, self.y_train)\n",
    "        test_dataset = TensorDataset(self.X_test, self.y_test)\n",
    "        \n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        self.test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptoPriceMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CryptoPriceMLP, self).__init__()\n",
    "        \n",
    "        # One hidden layer network\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Training Pipeline\n",
    "class ModelTrainer:\n",
    "    def __init__(self, model, learning_rate=0.01):\n",
    "        self.model = model\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    def train(self, train_loader, epochs=100):\n",
    "        self.model.train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            \n",
    "            for batch_X, batch_y in train_loader:\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(batch_X)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = self.criterion(outputs.squeeze(), batch_y)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Optimize\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "            \n",
    "            # Print loss every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in test_loader:\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = nn.MSELoss()(outputs.squeeze(), batch_y)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        print(f'Test Loss: {total_loss/len(test_loader):.4f}')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model(X)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, data_pipeline, trainer):\n",
    "        self.model = model\n",
    "        self.data_pipeline = data_pipeline\n",
    "        self.trainer = trainer\n",
    "        \n",
    "    def plot_training_progress(self, training_losses):\n",
    "        \"\"\"\n",
    "        Plot training loss over epochs\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(training_losses, label='Training Loss')\n",
    "        plt.title('Training Loss Over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_loss.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_actual_vs_predicted(self):\n",
    "        \"\"\"\n",
    "        Create scatter plot of actual vs predicted values\n",
    "        \"\"\"\n",
    "        # Predict on test data\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(self.data_pipeline.X_test).numpy()\n",
    "        \n",
    "        # Inverse transform predictions and actual values\n",
    "        y_pred = self.data_pipeline.scaler_y.inverse_transform(predictions)\n",
    "        y_true = self.data_pipeline.scaler_y.inverse_transform(\n",
    "            self.data_pipeline.y_test.numpy().reshape(-1, 1)\n",
    "        )\n",
    "        \n",
    "        # Create scatter plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(y_true, y_pred, alpha=0.5)\n",
    "        plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], \n",
    "                 'r--', lw=2)\n",
    "        plt.title('Actual vs Predicted Prices')\n",
    "        plt.xlabel('Actual Prices')\n",
    "        plt.ylabel('Predicted Prices')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('actual_vs_predicted.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_residuals(self):\n",
    "        \"\"\"\n",
    "        Create residual plot to assess model performance\n",
    "        \"\"\"\n",
    "        # Predict on test data\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(self.data_pipeline.X_test).numpy()\n",
    "        \n",
    "        # Inverse transform predictions and actual values\n",
    "        y_pred = self.data_pipeline.scaler_y.inverse_transform(predictions)\n",
    "        y_true = self.data_pipeline.scaler_y.inverse_transform(\n",
    "            self.data_pipeline.y_test.numpy().reshape(-1, 1)\n",
    "        )\n",
    "        \n",
    "        # Calculate residuals\n",
    "        residuals = y_true - y_pred\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "        plt.title('Residual Plot')\n",
    "        plt.xlabel('Predicted Values')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('residuals.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_performance_metrics(self):\n",
    "        \"\"\"\n",
    "        Calculate and print performance metrics\n",
    "        \"\"\"\n",
    "        # Predict on test data\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(self.data_pipeline.X_test).numpy()\n",
    "        \n",
    "        # Inverse transform predictions and actual values\n",
    "        y_pred = self.data_pipeline.scaler_y.inverse_transform(predictions)\n",
    "        y_true = self.data_pipeline.scaler_y.inverse_transform(\n",
    "            self.data_pipeline.y_test.numpy().reshape(-1, 1)\n",
    "        )\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        \n",
    "        # Create metrics dataframe\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Metric': ['Mean Squared Error', 'Mean Absolute Error', 'R-squared'],\n",
    "            'Value': [mse, mae, r2]\n",
    "        })\n",
    "        \n",
    "        # Save metrics to CSV\n",
    "        metrics_df.to_csv('model_performance_metrics.csv', index=False)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(\"Model Performance Metrics:\")\n",
    "        print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0002\n",
      "Epoch [20/100], Loss: 0.0001\n",
      "Epoch [30/100], Loss: 0.0002\n",
      "Epoch [40/100], Loss: 0.0002\n",
      "Epoch [50/100], Loss: 0.0001\n",
      "Epoch [60/100], Loss: 0.0001\n",
      "Epoch [70/100], Loss: 0.0001\n",
      "Epoch [80/100], Loss: 0.0001\n",
      "Epoch [90/100], Loss: 0.0002\n",
      "Epoch [100/100], Loss: 0.0001\n",
      "Test Loss: 0.0006\n",
      "Model Performance Metrics:\n",
      "             Metric      Value\n",
      " Mean Squared Error 953.453857\n",
      "Mean Absolute Error  24.895945\n",
      "          R-squared   0.999380\n"
     ]
    }
   ],
   "source": [
    "csv_path = '../data/crypto_data.csv'\n",
    "data_pipeline = CryptoPricePredictionPipeline(csv_path)\n",
    "data_pipeline.prepare_data()\n",
    "\n",
    "input_size = data_pipeline.X_train.shape[1]\n",
    "hidden_size = 64  # You can tune this\n",
    "output_size = 1\n",
    "\n",
    "model = CryptoPriceMLP(input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "trainer = ModelTrainer(model)\n",
    "\n",
    "# Train the Model\n",
    "trainer.train(data_pipeline.train_loader, epochs=100)\n",
    "\n",
    "# Evaluate Model\n",
    "trainer.evaluate(data_pipeline.test_loader)\n",
    "\n",
    "\n",
    "evaluator = ModelEvaluator(model, data_pipeline, trainer)\n",
    "\n",
    "# Generate Visualizations\n",
    "#evaluator.plot_training_progress(training_losses)\n",
    "evaluator.plot_actual_vs_predicted()\n",
    "evaluator.plot_residuals()\n",
    "\n",
    "# Generate Performance Metrics\n",
    "evaluator.generate_performance_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
